# ğŸ§  NeuraVoice

[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](#license) [![Python](https://img.shields.io/badge/Python-3.9%2B-blue.svg)](https://www.python.org/) [![GUI](https://img.shields.io/badge/GUI-Tkinter%20%2B%20Pillow-orange)](#technology-stack) [![LLM](https://img.shields.io/badge/LLM-Ollama%20(local)-purple)](#technology-stack)

NeuraVoice is a nextâ€‘gen AI desktop voice assistant built with Python. It combines realâ€‘time speech recognition, natural language processing, a modern Tkinter GUI, and local LLM responses via Ollama to deliver fast, private, and reliable conversations and task automation on your computer.

---

## Overview
NeuraVoice acts as your personal intelligent assistant. Speak naturally to open websites, search Wikipedia, play local music, check date/time, control system actions (shutdown/restart/sleep), and chat using a locally hosted LLM (Ollama). It features a scrollable chat UI, status indicators, and oneâ€‘click action buttons.

Unique highlights:
- Local, privacyâ€‘first LLM responses via Ollama (e.g., `llama3.2:3b`)
- Alwaysâ€‘on voice listening with clear status cues in a desktop GUI
- Blends command execution with conversational chat in one app

---

## Key Features
- ğŸ™ï¸ Voice: Realâ€‘time speech recognition with adjustable listen/cooldown durations
- ğŸ”Š TTS: Natural responses with `pyttsx3`
- ğŸ§  LLM: Local generation through Ollama with safe fallback responses
- ğŸ§© Tasks: Wikipedia summaries; open YouTube/Google/Facebook/Instagram/Twitter; launch VS Code or any configured app; play music from a folder; report date/time
- ğŸ–¥ï¸ GUI: Tkinter + Pillow interface, scrollable history, live status (Listening/Processing/Idle), quickâ€‘action buttons
- ğŸ§© Context: Lightweight intent normalization (e.g., â€œwhatâ€™s the timeâ€ â†’ `time`)

---

## Demo
![NeuraVoice GUI](docs/screenshot.png)

If you donâ€™t have a screenshot yet, add one at `docs/screenshot.png` after capturing the app window.

---

## Technology Stack
- Language: Python 3.9+
- GUI: Tkinter, Pillow (PIL)
- Speech: `speech_recognition`
- TTS: `pyttsx3`
- LLM: Ollama (local), default model `llama3.2:3b`
- Utils: `wikipedia`, `webbrowser`, `os`, `datetime`, etc.

---

## Installation
1. Install Python 3.9+ and Git.
2. Clone the repository:
   ```bash
   git clone https://github.com/arpanpramanik2003/NeuraVoice.git
   cd NeuraVoice
   ```
3. (Recommended) Create and activate a virtual environment:
   ```bash
   python -m venv .venv
   # Windows
   .venv\Scripts\activate
   # macOS/Linux
   source .venv/bin/activate
   ```
4. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
5. Install and run Ollama (for local LLM):
   - Install: https://ollama.com
   - Start the server and pull a model:
     ```bash
     ollama serve &
     ollama pull llama3.2:3b
     ```

---

## Usage
1. Start Ollama (if not already running):
   ```bash
   ollama serve
   ```
2. Launch NeuraVoice:
   ```bash
   python main.py
   ```
3. In the GUI:
   - Click â€œSingle Listenâ€ or enable continuous listening
   - Speak a command or ask a question
   - Watch status change (Listening â†’ Processing â†’ Idle) and view responses in the chat window

---

## Supported Commands (Examples)
- Open websites:
  - â€œOpen YouTubeâ€, â€œOpen Googleâ€, â€œOpen Instagramâ€, â€œOpen Facebookâ€, â€œOpen Twitterâ€
- System info:
  - â€œWhatâ€™s the time?â€, â€œTell me todayâ€™s dateâ€
- Wikipedia:
  - â€œSearch Wikipedia for Alan Turingâ€
- Music:
  - â€œPlay musicâ€ (plays from configured folder)
- Apps:
  - â€œOpen VS Codeâ€ (or any configured app)
- System controls:
  - â€œShutdown the systemâ€, â€œRestartâ€, â€œSleepâ€
- General chat (via Ollama):
  - â€œExplain quantum computing in simple terms.â€

Note: Natural phrasing is supported; commands are normalized internally.

---

## Configuration
- Ollama model: Set default model name (e.g., `llama3.2:3b`) in the config section of the code.
- Music directory: Update the path used for playing music.
- App shortcuts: Add or change mappings (e.g., path to VS Code) in the app launcher logic.
- Listening timings: Tune listen duration and cooldown values.

Add a `config.example.json` if you want environmentâ€‘based configuration; document keys like:
```json
{
  "ollama_model": "llama3.2:3b",
  "music_dir": "C:/Users/you/Music",
  "vscode_path": "C:/Users/you/AppData/Local/Programs/Microsoft VS Code/Code.exe"
}
```

---

## Project Structure
```
NeuraVoice/
â”œâ”€ main.py               # App entry point (GUI + controller)
â”œâ”€ assistants/           # Intent handling, actions, and LLM client
â”œâ”€ assets/               # Icons, images
â”œâ”€ docs/
â”‚  â””â”€ screenshot.png     # Demo UI screenshot
â”œâ”€ requirements.txt      # Python dependencies
â””â”€ README.md             # This file
```
(Adjust based on your actual files.)

---

## Troubleshooting
- Microphone not detected: Check OS input settings and device permissions.
- No TTS audio: Ensure speakers are set as default output; try a different `pyttsx3` voice/driver.
- Ollama errors or slow replies: Confirm `ollama serve` is running and the model is pulled; try a smaller model.
- Wikipedia timeouts: Retry or check internet connectivity.
- GUI freezes: Avoid longâ€‘running work on the main thread; consider threading for blocking calls.

---

## Contributing
Contributions are welcome! Please:
1. Fork the repo and create a feature branch.
2. Follow a clean commit style and include tests or demo steps where possible.
3. Open a pull request with a clear description and screenshots if UI changes.

---

## Roadmap
- Hotâ€‘word activation (optional wake word)
- Pluggable skills system and command registry
- Multiâ€‘model support (switch Ollama models at runtime)
- Conversation memory with history controls
- Crossâ€‘platform packaging (Windows/macOS/Linux installers)

---

## License
This project is licensed under the MIT License. See the [LICENSE](LICENSE) file.

## Acknowledgments
- Ollama team for local LLM infrastructure
- Python community and maintainers of `speech_recognition`, `pyttsx3`, `wikipedia`
- Tkinter/Pillow contributors for accessible desktop UI
